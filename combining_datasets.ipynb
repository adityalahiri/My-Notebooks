{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'tempm', 'tempi', 'dewptm', 'dewpti', 'hum', 'wspdm',\n",
       "       'wspdi', 'wgustm', 'wgusti', 'wdird', 'wdire', 'vism', 'visi',\n",
       "       'pressurem', 'pressurei', 'windchillm', 'windchilli', 'heatindexm',\n",
       "       'heatindexi', 'precipm', 'precipi', 'conds', 'icon', 'fog', 'rain',\n",
       "       'snow', 'hail', 'thunder', 'tornado'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "csvPath = '/home/arrayslayer/ML Competitions/Kaggle NYC/'\n",
    "dweath = pandas.DataFrame(pandas.read_csv(csvPath + \"Weather\" + \".csv\"))\n",
    "dweath.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, numpy, datetime\n",
    "\n",
    "### Train Data Wrangling ###\n",
    "# Open raw Train data\n",
    "csvPath = '/home/arrayslayer/ML Competitions/Kaggle NYC/'\n",
    "dtrain = pandas.DataFrame(pandas.read_csv(csvPath +\"train.zip\", compression = 'zip'))\n",
    "# Prepare Train data\n",
    "dtrain[\"pickup_datetime\"] = pandas.to_datetime(dtrain[\"pickup_datetime\"])\n",
    "dtrain[\"dropoff_datetime\"] = pandas.to_datetime(dtrain[\"dropoff_datetime\"])\n",
    "dtrain[\"Month\"]=pandas.to_datetime(dtrain[\"pickup_datetime\"]).dt.month\n",
    "dtrain[\"Week\"]=pandas.to_datetime(dtrain[\"pickup_datetime\"]).dt.week\n",
    "dtrain[\"Weekday\"]=pandas.to_datetime(dtrain[\"pickup_datetime\"]).dt.weekday_name\n",
    "dtrain[\"Hour\"]=pandas.to_datetime(dtrain[\"pickup_datetime\"]).dt.hour\n",
    "# Save wrangled Train data\n",
    "dtrain.to_csv(csvPath + \"dtrain.csv\") # Save to csv\n",
    "\n",
    "### Test Data Wrangling ###\n",
    "# Open raw Test data\n",
    "csvPath = '/home/arrayslayer/ML Competitions/Kaggle NYC/'\n",
    "dtest = pandas.DataFrame(pandas.read_csv(csvPath +\"test.zip\", compression = 'zip'))\n",
    "# Prepare Train data\n",
    "dtest[\"pickup_datetime\"] = pandas.to_datetime(dtrain[\"pickup_datetime\"])\n",
    "#dtrain[\"dropoff_datetime\"] = pandas.to_datetime(dtrain[\"dropoff_datetime\"])\n",
    "dtest[\"Month\"]=pandas.to_datetime(dtest[\"pickup_datetime\"]).dt.month\n",
    "dtest[\"Week\"]=pandas.to_datetime(dtest[\"pickup_datetime\"]).dt.week\n",
    "dtest[\"Weekday\"]=pandas.to_datetime(dtest[\"pickup_datetime\"]).dt.weekday_name\n",
    "dtest[\"Hour\"]=pandas.to_datetime(dtest[\"pickup_datetime\"]).dt.hour\n",
    "# Save wrangled Test data\n",
    "dtest.to_csv(csvPath + \"dtest.csv\") # Save to csv\n",
    "\n",
    "### Weather Data Wrangling ###\n",
    "# Open raw Weather data\n",
    "csvPath = '/home/arrayslayer/ML Competitions/Kaggle NYC/'\n",
    "dweath = pandas.DataFrame(pandas.read_csv(csvPath + \"Weather\" + \".csv\"))\n",
    "# Prepare Weather data\n",
    "dweath['pickup_datetime'] = pandas.to_datetime(dweath[\"pickup_datetime\"])\n",
    "#dweath=dweath.rename(columns={'Datetime': 'pickup_datetime'}) # Renames Datetime column to pickup_datetime\n",
    "dweath = dweath.replace(-999.0, numpy.nan)\n",
    "dweath = dweath.replace(-9999.0, numpy.nan)\n",
    "dweath = dweath.drop_duplicates(subset='pickup_datetime', keep='last')\n",
    "dweath.sort_values(by='pickup_datetime', inplace=True)\n",
    "# Save wrangled Weather data\n",
    "csvPath = '/home/arrayslayer/ML Competitions/Kaggle NYC/'\n",
    "pandas.DataFrame(dweath).to_csv(csvPath + \"Weather_mod\" + \".csv\", header=True, index=False, encoding='utf-8') # Save to csv\n",
    "\n",
    "# Sort data before merge\n",
    "dtrain.sort_values(by='pickup_datetime', inplace=True)\n",
    "dtest.sort_values(by='pickup_datetime', inplace=True)\n",
    "dweath.sort_values(by='pickup_datetime', inplace=True)\n",
    "dmerge=pandas.merge_asof(dtrain,dweath, on=\"pickup_datetime\", tolerance=pandas.Timedelta('31m'))\n",
    "tmerge=pandas.merge_asof(dtest,dweath, on=\"pickup_datetime\", tolerance=pandas.Timedelta('31m'))\n",
    "\n",
    "\n",
    "# Save merged data\n",
    "csvPath = '/home/arrayslayer/ML Competitions/Kaggle NYC/'\n",
    "dmerge.to_csv(csvPath + \"dmerge\" + \".csv\", header=True, index=False, encoding='utf-8')\n",
    "tmerge.to_csv(csvPath + \"tmerge\" + \".csv\", header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>precipm</th>\n",
       "      <th>precipi</th>\n",
       "      <th>conds</th>\n",
       "      <th>icon</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>tornado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id0190469</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:00:17</td>\n",
       "      <td>2016-01-01 00:14:26</td>\n",
       "      <td>5</td>\n",
       "      <td>-73.981743</td>\n",
       "      <td>40.719158</td>\n",
       "      <td>-73.938828</td>\n",
       "      <td>40.829182</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id1665586</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:00:53</td>\n",
       "      <td>2016-01-01 00:22:27</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.985085</td>\n",
       "      <td>40.747166</td>\n",
       "      <td>-73.958038</td>\n",
       "      <td>40.717491</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id1210365</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01 00:01:01</td>\n",
       "      <td>2016-01-01 00:07:49</td>\n",
       "      <td>5</td>\n",
       "      <td>-73.965279</td>\n",
       "      <td>40.801041</td>\n",
       "      <td>-73.947479</td>\n",
       "      <td>40.815170</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id3888279</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:01:14</td>\n",
       "      <td>2016-01-01 00:05:54</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.982292</td>\n",
       "      <td>40.751331</td>\n",
       "      <td>-73.991341</td>\n",
       "      <td>40.750340</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id0924227</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01 00:01:20</td>\n",
       "      <td>2016-01-01 00:13:36</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.970108</td>\n",
       "      <td>40.759800</td>\n",
       "      <td>-73.989357</td>\n",
       "      <td>40.742989</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
       "0  id0190469          2  2016-01-01 00:00:17  2016-01-01 00:14:26   \n",
       "1  id1665586          1  2016-01-01 00:00:53  2016-01-01 00:22:27   \n",
       "2  id1210365          2  2016-01-01 00:01:01  2016-01-01 00:07:49   \n",
       "3  id3888279          1  2016-01-01 00:01:14  2016-01-01 00:05:54   \n",
       "4  id0924227          1  2016-01-01 00:01:20  2016-01-01 00:13:36   \n",
       "\n",
       "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0                5        -73.981743        40.719158         -73.938828   \n",
       "1                1        -73.985085        40.747166         -73.958038   \n",
       "2                5        -73.965279        40.801041         -73.947479   \n",
       "3                1        -73.982292        40.751331         -73.991341   \n",
       "4                1        -73.970108        40.759800         -73.989357   \n",
       "\n",
       "   dropoff_latitude store_and_fwd_flag   ...     precipm  precipi     conds  \\\n",
       "0         40.829182                  N   ...         NaN      NaN  Overcast   \n",
       "1         40.717491                  N   ...         NaN      NaN  Overcast   \n",
       "2         40.815170                  N   ...         NaN      NaN  Overcast   \n",
       "3         40.750340                  N   ...         NaN      NaN  Overcast   \n",
       "4         40.742989                  N   ...         NaN      NaN  Overcast   \n",
       "\n",
       "     icon  fog  rain  snow  hail  thunder  tornado  \n",
       "0  cloudy  0.0   0.0   0.0   0.0      0.0      0.0  \n",
       "1  cloudy  0.0   0.0   0.0   0.0      0.0      0.0  \n",
       "2  cloudy  0.0   0.0   0.0   0.0      0.0      0.0  \n",
       "3  cloudy  0.0   0.0   0.0   0.0      0.0      0.0  \n",
       "4  cloudy  0.0   0.0   0.0   0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pandas.read_csv('dmerge.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'vendor_id', 'pickup_datetime', 'dropoff_datetime',\n",
       "       'passenger_count', 'pickup_longitude', 'pickup_latitude',\n",
       "       'dropoff_longitude', 'dropoff_latitude', 'store_and_fwd_flag',\n",
       "       'trip_duration', 'Month', 'Week', 'Weekday', 'Hour', 'tempm', 'tempi',\n",
       "       'dewptm', 'dewpti', 'hum', 'wspdm', 'wspdi', 'wgustm', 'wgusti',\n",
       "       'wdird', 'wdire', 'vism', 'visi', 'pressurem', 'pressurei',\n",
       "       'windchillm', 'windchilli', 'heatindexm', 'heatindexi', 'precipm',\n",
       "       'precipi', 'conds', 'icon', 'fog', 'rain', 'snow', 'hail', 'thunder',\n",
       "       'tornado'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
